version: '3.8'

services:
  ml-gpu:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: 25h2_ai_gpu
    volumes:
      - .:/workspace
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
    environment:
      - DISPLAY=${DISPLAY}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - TF_FORCE_GPU_ALLOW_GROWTH=true
    runtime: nvidia
    ports:
      - "8888:8888"
    stdin_open: true
    tty: true
    working_dir: /workspace